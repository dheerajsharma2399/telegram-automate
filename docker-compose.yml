# Docker Compose configuration for Telegram Job Scraper
# Multi-service deployment with web dashboard and Telegram bot

version: '3.8'

services:
  # Web Dashboard Service
  web-dashboard:
    build:
      context: .
      dockerfile: Dockerfile.web
    container_name: telegram-job-dashboard
    ports:
      - "5000:5000"
    environment:
      # Database Configuration
      - DATABASE_PATH=/app/data/jobs.db
      
      # Flask Configuration
      - FLASK_ENV=development
      - FLASK_DEBUG=0
      - PORT=5000
      
      # Security Configuration
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY:-super-secret}
      
      # Telegram Configuration (for API calls)
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - ADMIN_USER_ID=${ADMIN_USER_ID}
      
      # LLM Configuration
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-anthropic/claude-3.5-sonnet}
      - OPENROUTER_FALLBACK_MODEL=${OPENROUTER_FALLBACK_MODEL:-openai/gpt-4o-mini}
      
      # Google Sheets Configuration
      - GOOGLE_CREDENTIALS_JSON=${GOOGLE_CREDENTIALS_JSON}
      - SPREADSHEET_ID=${SPREADSHEET_ID}
    volumes:
      # Persistent data storage
      - db-data:/app/data
      - logs-data:/app/logs
      - ./user_profile.json:/app/user_profile.json:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - telegram-network
    depends_on:
      - db-monitor

  # Telegram Bot Service
  telegram-bot:
    build:
      context: .
      dockerfile: Dockerfile.bot
    container_name: telegram-job-bot
    environment:
      # Database Configuration
      - DATABASE_PATH=/app/data/jobs.db
      
      # Telegram API Configuration
      - TELEGRAM_API_ID=${TELEGRAM_API_ID}
      - TELEGRAM_API_HASH=${TELEGRAM_API_HASH}
      - TELEGRAM_PHONE=${TELEGRAM_PHONE}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_GROUP_USERNAME=${TELEGRAM_GROUP_USERNAME}
      - TELEGRAM_GROUP_USERNAMES=${TELEGRAM_GROUP_USERNAMES}
      
      # Authorization
      - AUTHORIZED_USER_IDS=${AUTHORIZED_USER_IDS}
      - ADMIN_USER_ID=${ADMIN_USER_ID}
      
      # LLM Configuration
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-anthropic/claude-3.5-sonnet}
      - OPENROUTER_FALLBACK_MODEL=${OPENROUTER_FALLBACK_MODEL:-openai/gpt-4o-mini}
      
      # Processing Configuration
      - BATCH_SIZE=10
      - PROCESSING_INTERVAL_MINUTES=5
      - MAX_RETRIES=3
      
      # Google Sheets Configuration
      - GOOGLE_CREDENTIALS_JSON=${GOOGLE_CREDENTIALS_JSON}
      - SPREADSHEET_ID=${SPREADSHEET_ID}
    volumes:
      # Persistent data storage
      - db-data:/app/data
      - logs-data:/app/logs
      - ./user_profile.json:/app/user_profile.json:ro
      # Telegram session files
      - telegram-sessions:/app/sessions
    restart: unless-stopped
    networks:
      - telegram-network
    depends_on:
      - db-monitor

  # Database Monitor Service
  db-monitor:
    image: alpine:latest
    container_name: telegram-db-monitor
    volumes:
      - db-data:/app/data
      - logs-data:/app/logs
      - ./database-backup:/backup
    command: |
      sh -c "
        echo 'Database monitor started'
        # Keep container running
        tail -f /dev/null
      "
    restart: unless-stopped
    networks:
      - telegram-network

  # Optional: Log Aggregation Service
  # Uncomment if you want centralized logging
  # fluentd:
  #   image: fluent/fluentd:v1.12-debian-1
  #   container_name: telegram-logs
  #   volumes:
  #     - ./fluentd/conf:/fluentd/etc
  #     - logs-data:/fluentd/log
  #   ports:
  #     - "24224:24224"
  #   networks:
  #     - telegram-network

# Named volumes for persistent data
volumes:
  db-data:
    driver: local
  logs-data:
    driver: local
  telegram-sessions:
    driver: local

# Network configuration
networks:
  telegram-network:
    driver: bridge
    internal: false
    ipam:
      config:
        - subnet: 172.20.0.0/16